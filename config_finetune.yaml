batch_size: 128              
epochs: 50
fine_tune_from :
  # None
  model_weight/pretrain/pretrain_acid.pth       #acid
#  model_weight/pretrain/pretrain_base.pth          #base


init_lr: 0.0003            
lr_decay_factor : 0.3
min_lr :  0.0001
weight_decay: 0      
seed :  1                  
lr_dacay_patience : 10
early_stop_patience : 15


sat:
  dim_hidden : 128
  in_size : 40
  num_class : 1            
  num_heads : 8
  abs_pe : rw               #rw,lap
  abs_pe_dim : 20
  d_model : 64
  dim_feedforward : 256     #2*dim_hidden
  num_layers : 4
  dropout : 0.2
  batch_norm : True
  gnn_type : graphsage      #gcn,gine,graphsage,gin
  use_edge_attr : True
  num_edge_features : 10    #number of edge labels
  edge_dim : 32
  k_hop : 3
  se  :  khopgnn            #k-subtree structure extractor
  global_pool : add


